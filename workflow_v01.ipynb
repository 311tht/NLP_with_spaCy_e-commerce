{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e449bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from spacy.training.example import Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b214772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_txt  = [\n",
    "    (\"I love this brand of toothpaste\", {\"entities\": [(21, 31, \"PRODUCT\")]}),\n",
    "    (\"The coffee maker makes great coffee\", {\"entities\": [(4, 15, \"PRODUCT\")]}),\n",
    "    (\"I need to buy a new printer\", {\"entities\": [(20, 27, \"PRODUCT\")]}),\n",
    "    (\"This lotion is very moisturizing\", {\"entities\": [(5, 11, \"PRODUCT\")]}),\n",
    "    (\"I use this brand of shampoo all the time\", {\"entities\": [(20, 27, \"PRODUCT\")]}),\n",
    "    (\"This camera takes high-quality photos\", {\"entities\": [(5, 11, \"PRODUCT\")]}),\n",
    "    (\"I want to buy a new pair of headphones\", {\"entities\": [(28, 38, \"PRODUCT\")]}),\n",
    "    (\"This brand of cereal is my favorite\", {\"entities\": [(14, 20, \"PRODUCT\")]}),\n",
    "    (\"I need to get more printer paper\", {\"entities\": [(27, 32, \"PRODUCT\")]}),\n",
    "    (\"This brand of juice is really good\", {\"entities\": [(14, 19, \"PRODUCT\")]}),\n",
    "    (\"These headphones have great sound quality\", {\"entities\": [(6, 16, \"PRODUCT\")]}),\n",
    "    (\"I want to buy a new laptop\", {\"entities\": [(20, 26, \"PRODUCT\")]}),\n",
    "    (\"This soap smells really nice\", {\"entities\": [(5, 9, \"PRODUCT\")]}),\n",
    "    (\"I love this brand of tea\", {\"entities\": [(21, 24, \"PRODUCT\")]}),\n",
    "    (\"This brand of chips is really tasty\", {\"entities\": [(14, 19, \"PRODUCT\")]}),\n",
    "    (\"I need more printer ink\", {\"entities\": [(20, 23, \"PRODUCT\")]}),\n",
    "    (\"This jacket is really warm\", {\"entities\": [(5, 11, \"PRODUCT\")]}),\n",
    "    (\"I want to buy a new phone\", {\"entities\": [(20, 25, \"PRODUCT\")]}),\n",
    "    (\"This brand of cookies is delicious\", {\"entities\": [(14, 21, \"PRODUCT\")]}),\n",
    "    (\"This brand of paper towels is my favorite\", {\"entities\": [(14, 26, \"PRODUCT\")]}),\n",
    "    (\"I need to buy a new pair of shoes\", {\"entities\": [(28, 33, \"PRODUCT\")]}),\n",
    "    (\"This brand of yogurt is really good\", {\"entities\": [(14, 20, \"PRODUCT\")]}),\n",
    "    (\"These headphones are very comfortable\", {\"entities\": [(6, 16, \"PRODUCT\")]}),\n",
    "    (\"I love this brand of chips\", {\"entities\": [(21, 27, \"PRODUCT\")]}),\n",
    "    (\"This brand of bread is my favorite\", {\"entities\": [(14, 19, \"PRODUCT\")]}),\n",
    "    (\"This camera has great features\", {\"entities\": [(5, 11, \"PRODUCT\")]}),\n",
    "    (\"I want to try this new brand of coffee\", {\"entities\": [(32, 38, \"PRODUCT\")]}),\n",
    "    (\"This brand of ice cream is really tasty\", {\"entities\": [(14, 23, \"PRODUCT\")]}),\n",
    "    (\"I need to get more laundry detergent\", {\"entities\": [(27, 36, \"PRODUCT\")]}),\n",
    "    (\"This brand of cheese is really good\", {\"entities\": [(14, 20, \"PRODUCT\")]}),\n",
    "    (\"I want to buy a new pair of running shoes\", {\"entities\": [(28, 41, \"PRODUCT\")]}),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6103cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    " def load_mappings(dataset):\n",
    "    f = open(dataset, 'r',encoding='utf-8')\n",
    "    model= dict({})\n",
    "    for line in f:\n",
    "        tem=line.split()\n",
    "        vtem=[]\n",
    "        for i in range(1,len(tem)):\n",
    "            vtem.append( float(tem[i].strip()))\n",
    "        vec1=np.array(vtem)\n",
    "        model.update({tem[0].strip():vec1})\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bf47e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (label, train_data, model):\n",
    "    # Add the new label to the entity recognizer\n",
    "    # Load the pre-trained model\n",
    "    nlp = spacy.load(model)\n",
    "\n",
    "    nlp_train = spacy.load(model)\n",
    "\n",
    "    ner = nlp_train.get_pipe(\"ner\")\n",
    "    ner.add_label(label)\n",
    "\n",
    "    # Fine-tune the model\n",
    "    optimizer = nlp_train.resume_training()\n",
    "    for i in range(10):\n",
    "        for example in train_data:\n",
    "            doc = nlp_train(example[0])\n",
    "            gold = Example.from_dict(doc, example[1])\n",
    "            nlp_train.update([gold], sgd=optimizer)\n",
    "    return nlp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a2c86a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product(text : str, train_model) -> str :\n",
    "    # Test the model train\n",
    "    list_test = []\n",
    "#   label = [\"PRODUCT\",\"PRICE\"]\n",
    "    doc = train_model(text)        \n",
    "    for ent in doc.ents:\n",
    "        #if ent.label_ in label:\n",
    "        list_test.append([ent.text, ent.label_])\n",
    "    return list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac2f53ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_product_category \n",
    "def get_product_category(my_product, my_list):\n",
    "    for i in my_product:\n",
    "        if i[1] == \"PRODUCT\":\n",
    "            product = i[0]\n",
    "    if product in load_model: \n",
    "        embeddings = []\n",
    "        v1 = load_model[product.strip()]\n",
    "        embeddings.append(v1)\n",
    "        for category in my_list:\n",
    "            embeddings.append(load_model[category.strip()])\n",
    "        cos_sim = cosine_similarity( [embeddings[0]], embeddings[1:])\n",
    "        return my_list[np.argmax(cos_sim)]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d8d2e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Workflow(label, model, train_data, test_text):\n",
    "    nlp_train = train(label, train_data, model)\n",
    "    nlp_test = get_product(test_text,nlp_train)\n",
    "    return nlp_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0dd1a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catch_cat(predict, data):\n",
    "    for i in data:\n",
    "        for u in data:\n",
    "            if u['category'] == predict:\n",
    "                return u['item_attributes']\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c3bfcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_att(att,my_product):\n",
    "    my_dict = {'PRODUCT':'','item_attributes':{}}\n",
    "    for i in my_product:\n",
    "        if i[-1] == 'PRODUCT':\n",
    "            my_dict['PRODUCT'] = i[0]\n",
    "        if i[-1] in att:\n",
    "            my_dict['item_attributes'][i[-1]] = i[0]\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31043b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load w2v\n",
    "load_model = load_mappings(\"glove.6B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c1292a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "31466dfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minh/anaconda3/lib/python3.10/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "/home/minh/anaconda3/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The coffee maker makes great coffee\" with entities \"[(4, 15, 'PRODUCT')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/minh/anaconda3/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"I love this brand of chips\" with entities \"[(21, 27, 'PRODUCT')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'product' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m train(LABEL,data_txt,model_name)\n\u001b[1;32m     41\u001b[0m my_product \u001b[38;5;241m=\u001b[39m get_product(test_text, model)\n\u001b[0;32m---> 42\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[43mget_product_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_product\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmy_product\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[54], line 6\u001b[0m, in \u001b[0;36mget_product_category\u001b[0;34m(my_product, my_list)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRODUCT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      5\u001b[0m         product \u001b[38;5;241m=\u001b[39m i[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mproduct\u001b[49m \u001b[38;5;129;01min\u001b[39;00m load_model: \n\u001b[1;32m      7\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m     v1 \u001b[38;5;241m=\u001b[39m load_model[product\u001b[38;5;241m.\u001b[39mstrip()]\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'product' referenced before assignment"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Define the new entity label\n",
    "    LABEL = \"PRODUCT\"\n",
    "    # Define model\n",
    "#     model_name = \"en_core_web_sm\"\n",
    "    # Define the training data\n",
    "    model_name = \"en_core_web_trf\"\n",
    "\n",
    "    #with open(\"train_Data.txt\") as data_train:\n",
    "      #  data_txt = data_train.read()\n",
    "#     TRAIN_DATA = data_txt\n",
    "    TRAIN_DATA = [\n",
    "    (\n",
    "        \"This is a great product\",\n",
    "        {\n",
    "            \"entities\": [(10, 17, \"PRODUCT\")]\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"I love this shampoo\",\n",
    "        {\n",
    "            \"entities\": [(12, 19, \"PRODUCT\")]\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"The phone has a great camera\",\n",
    "        {\n",
    "            \"entities\": [(4, 9, \"PRODUCT\")]\n",
    "        },\n",
    "    ),\n",
    "    (   \"My favorite phone is red\",\n",
    "        {\n",
    "            \"entities\": [(21, 24, \"COLOR\")]\n",
    "        },\n",
    "        )\n",
    "    ]\n",
    "    category_list = [\"phone\", \"clothes\"]\n",
    "    \n",
    "    test_text = \"My favorite phone is red.\"\n",
    "    model = train(LABEL,data_txt,model_name)\n",
    "    my_product = get_product(test_text, model)\n",
    "    predict = get_product_category(my_product, category_list)\n",
    "    print(f\"item: {my_product}\")\n",
    "    print(f\"category: {predict}\")\n",
    "    # read category-list\n",
    "    with open('category-list.json') as file:\n",
    "        category_list = json.load(file)\n",
    "\n",
    "    catch = catch_cat(predict,category_list)\n",
    "    stores = store_att(catch,my_product)\n",
    "    # Write json data \n",
    "    with open(\"cate_list.json\", \"w\") as json_file:  \n",
    "    # Sử dụng json.dump() để ghi dữ liệu vào file   \n",
    "        json.dump(stores, json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0841625b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c930e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1000$', 'MONEY']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "beb34b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 2 column 5 (char 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_Data.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     data_js \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_js)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 5 (char 6)"
     ]
    }
   ],
   "source": [
    "with open(\"train_Data.txt\",\"r\") as f:\n",
    "    data_js = json.load(f)\n",
    "print(data_js)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
